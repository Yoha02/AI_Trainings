{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1: Marketing Content Generation with LLMs\n",
        "\n",
        "Welcome to your first hands-on experience with Large Language Models (LLMs)!\n",
        "\n",
        "**What you'll learn in this lab:**\n",
        "- How to set up and initialize Google's Vertex AI\n",
        "- How to write effective prompts for content generation\n",
        "- How to use system instructions to guide LLM behavior\n",
        "- How to get structured (JSON) outputs from LLMs\n",
        "- How to use few-shot prompting to improve results\n",
        "\n",
        "**Prerequisites:**\n",
        "- Basic Python knowledge\n",
        "- A Google Cloud project with Vertex AI enabled\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Understanding Key Concepts\n",
        "\n",
        "Before we dive in, let's understand some fundamental concepts:\n",
        "\n",
        "### What is an LLM (Large Language Model)?\n",
        "An LLM is an AI model trained on vast amounts of text data. It can understand and generate human-like text. Think of it as a very sophisticated autocomplete that can:\n",
        "- Answer questions\n",
        "- Write content (emails, articles, code)\n",
        "- Summarize information\n",
        "- Transform text from one format to another\n",
        "\n",
        "### What is a Prompt?\n",
        "A **prompt** is the input text you send to an LLM. The quality of your prompt directly affects the quality of the response. Good prompts are:\n",
        "- **Clear**: State exactly what you want\n",
        "- **Specific**: Include relevant details and context\n",
        "- **Structured**: Organize information logically\n",
        "\n",
        "### What are System Instructions?\n",
        "**System instructions** are special instructions that define the LLM's persona, behavior, and constraints. They're like giving the AI a \"job description\" before it starts working.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Step 1: Environment Setup\n",
        "\n",
        "First, we need to import the necessary libraries. We're using:\n",
        "- `vertexai`: Google's AI platform SDK\n",
        "- `GenerativeModel`: The class for interacting with Gemini models\n",
        "- `GenerationConfig`: Configuration options for controlling output format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-aiplatform\n",
            "  Using cached google_cloud_aiplatform-1.132.0-py2.py3-none-any.whl.metadata (46 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
            "  Using cached google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-auth<3.0.0,>=2.45.0 (from google-cloud-aiplatform)\n",
            "  Using cached google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-aiplatform)\n",
            "  Using cached proto_plus-1.27.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform)\n",
            "  Using cached protobuf-6.33.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: packaging>=14.3 in c:\\users\\asggm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (25.0)\n",
            "Collecting google-cloud-storage<4.0.0,>=1.32.0 (from google-cloud-aiplatform)\n",
            "  Using cached google_cloud_storage-3.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform)\n",
            "  Using cached google_cloud_bigquery-3.39.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform)\n",
            "  Using cached google_cloud_resource_manager-1.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting shapely<3.0.0 (from google-cloud-aiplatform)\n",
            "  Using cached shapely-2.1.2-cp311-cp311-win_amd64.whl.metadata (7.1 kB)\n",
            "Collecting google-genai<2.0.0,>=1.37.0 (from google-cloud-aiplatform)\n",
            "  Using cached google_genai-1.56.0-py3-none-any.whl.metadata (53 kB)\n",
            "Collecting pydantic<3 (from google-cloud-aiplatform)\n",
            "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\asggm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Collecting docstring_parser<1 (from google-cloud-aiplatform)\n",
            "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
            "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting requests<3.0.0,>=2.18.0 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
            "  Using cached grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
            "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
            "  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.45.0->google-cloud-aiplatform)\n",
            "  Using cached cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.45.0->google-cloud-aiplatform)\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.45.0->google-cloud-aiplatform)\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
            "  Using cached google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
            "  Using cached google_resumable_media-2.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\asggm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform)\n",
            "  Using cached grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform)\n",
            "  Using cached google_crc32c-1.8.0-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
            "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting httpx<1.0.0,>=0.28.1 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting distro<2,>=1.7.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting sniffio (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3->google-cloud-aiplatform)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3->google-cloud-aiplatform)\n",
            "  Using cached pydantic_core-2.41.5-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3->google-cloud-aiplatform)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting numpy>=1.21 (from shapely<3.0.0->google-cloud-aiplatform)\n",
            "  Using cached numpy-2.4.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
            "Collecting idna>=2.8 (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting certifi (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.45.0->google-cloud-aiplatform)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\asggm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
            "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
            "  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Using cached google_cloud_aiplatform-1.132.0-py2.py3-none-any.whl (8.2 MB)\n",
            "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Using cached google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
            "Using cached google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
            "Using cached google_cloud_bigquery-3.39.0-py3-none-any.whl (259 kB)\n",
            "Using cached google_cloud_resource_manager-1.15.0-py3-none-any.whl (397 kB)\n",
            "Using cached google_cloud_storage-3.7.0-py3-none-any.whl (303 kB)\n",
            "Using cached google_genai-1.56.0-py3-none-any.whl (426 kB)\n",
            "Using cached proto_plus-1.27.0-py3-none-any.whl (50 kB)\n",
            "Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
            "   ---------------------------------------- 0.0/436.9 kB ? eta -:--:--\n",
            "   - ------------------------------------- 20.5/436.9 kB 330.3 kB/s eta 0:00:02\n",
            "   ----- --------------------------------- 61.4/436.9 kB 656.4 kB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 317.4/436.9 kB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 436.9/436.9 kB 3.0 MB/s eta 0:00:00\n",
            "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Using cached pydantic_core-2.41.5-cp311-cp311-win_amd64.whl (2.0 MB)\n",
            "Using cached shapely-2.1.2-cp311-cp311-win_amd64.whl (1.7 MB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "Using cached cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
            "Using cached google_crc32c-1.8.0-cp311-cp311-win_amd64.whl (34 kB)\n",
            "Using cached google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\n",
            "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "Using cached grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
            "Using cached grpcio-1.76.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
            "Downloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached numpy-2.4.0-cp311-cp311-win_amd64.whl (12.6 MB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Using cached websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: websockets, urllib3, typing-inspection, tenacity, sniffio, pydantic-core, pyasn1, protobuf, numpy, idna, h11, grpcio, google-crc32c, docstring_parser, distro, charset_normalizer, certifi, cachetools, annotated-types, shapely, rsa, requests, pydantic, pyasn1-modules, proto-plus, httpcore, googleapis-common-protos, google-resumable-media, anyio, httpx, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-genai, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.12.0 cachetools-6.2.4 certifi-2025.11.12 charset_normalizer-3.4.4 distro-1.9.0 docstring_parser-0.17.0 google-api-core-2.28.1 google-auth-2.45.0 google-cloud-aiplatform-1.132.0 google-cloud-bigquery-3.39.0 google-cloud-core-2.5.0 google-cloud-resource-manager-1.15.0 google-cloud-storage-3.7.0 google-crc32c-1.8.0 google-genai-1.56.0 google-resumable-media-2.8.0 googleapis-common-protos-1.72.0 grpc-google-iam-v1-0.14.3 grpcio-1.76.0 grpcio-status-1.76.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 numpy-2.4.0 proto-plus-1.27.0 protobuf-6.33.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 requests-2.32.5 rsa-4.9.1 shapely-2.1.2 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.2 urllib3-2.6.2 websockets-15.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚úÖ Installation complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: C:\\Users\\asggm\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run this cell first, only needed once, this may take a while so don't worry if you dont see output immediately)\n",
        "%pip install google-cloud-aiplatform\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Step 2: Configure Your Project\n",
        "\n",
        "### Add the project id for your sandbox\n",
        "\n",
        "Every Google Cloud project has a unique **Project ID**. This tells Vertex AI which project to bill and which resources to use.\n",
        "\n",
        "**How to find your Project ID:**\n",
        "1. Go to [Google Cloud Console](https://console.cloud.google.com/)\n",
        "2. Look at the project selector at the top of the page\n",
        "3. Your Project ID is displayed there (it's different from the project name!)\n",
        "\n",
        " **Important**: Replace the empty string below with your actual Project ID.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace with your Google Cloud Project ID\n",
        "# Example: PROJECT_ID = \"my-project-123456\"\n",
        "PROJECT_ID = \"agents4good\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 3: Initialize Vertex AI\n",
        "\n",
        "Now we initialize the Vertex AI SDK with our project and specify which data center (location) to use.\n",
        "\n",
        "**About the model choices:**\n",
        "- `gemini-2.0-flash-001`: Fast, efficient, good for most tasks (we'll use this)\n",
        "- `gemini-2.5-flash`: Newer version, balanced speed and capability\n",
        "- `gemini-2.5-pro`: Most capable, but slower and more expensive\n",
        "\n",
        "üí° **Tip**: Start with `flash` models for development and testing - they're faster and cheaper!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Vertex AI initialized with project: agents4good\n",
            "üì¶ Using model: gemini-2.0-flash-001\n"
          ]
        }
      ],
      "source": [
        "# Initialize Vertex AI with your project\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
        "\n",
        "# Select a model to use: \"gemini-2.5-flash\", \"gemini-2.5-pro\", \"gemini-2.0-flash-001\"\n",
        "MODEL = \"gemini-2.0-flash-001\"\n",
        "\n",
        "print(f\"‚úÖ Vertex AI initialized with project: {PROJECT_ID}\")\n",
        "print(f\"üì¶ Using model: {MODEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Step 4: Create System Instructions\n",
        "\n",
        "### Add system instructions to optimize the LLM for a marketing content generation assistant\n",
        "\n",
        "System instructions set the \"personality\" and \"expertise\" of the AI. For a marketing assistant, we want to:\n",
        "- Define its role (marketing expert)\n",
        "- Set the tone (professional but engaging)\n",
        "- Establish constraints (brand-appropriate, accurate)\n",
        "\n",
        "**Example system instruction components:**\n",
        "- **Role**: \"You are a professional marketing copywriter...\"\n",
        "- **Expertise**: \"...specializing in retail and consumer products\"\n",
        "- **Tone**: \"Use an engaging, friendly tone that resonates with consumers\"\n",
        "- **Constraints**: \"Keep content concise and highlight key benefits\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System instructions set! The AI will now act as a marketing copywriter.\n"
          ]
        }
      ],
      "source": [
        "# System instructions define the AI's role and behavior\n",
        "system_instructions = \"\"\"\n",
        "You are a professional marketing copywriter specializing in retail and consumer products.\n",
        "\n",
        "Your expertise includes:\n",
        "- Creating compelling product descriptions\n",
        "- Writing engaging seasonal and holiday-themed content\n",
        "- Transforming product features into customer benefits\n",
        "\n",
        "Guidelines:\n",
        "- Use an engaging, friendly tone that resonates with everyday consumers\n",
        "- Highlight key benefits and unique selling points\n",
        "- Keep content concise but impactful\n",
        "- Make seasonal content feel festive and relevant\n",
        "\"\"\"\n",
        "\n",
        "print(\"System instructions set! The AI will now act as a marketing copywriter.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Initialize the Model\n",
        "\n",
        "Now we create our model instance with the system instructions. Every time we use this model, it will remember its \"marketing copywriter\" role.\n",
        "\n",
        "**What's happening here:**\n",
        "- `GenerativeModel()` creates a connection to the Gemini model\n",
        "- `system_instruction` parameter embeds our instructions into every conversation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model initialized and ready to generate content!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asggm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\vertexai\\generative_models\\_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "# Create the model with our system instructions\n",
        "model = GenerativeModel(MODEL, system_instruction=[system_instructions])\n",
        "\n",
        "print(\"‚úÖ Model initialized and ready to generate content!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Basic Prompting - Holiday Content Generation\n",
        "\n",
        "### Write a prompt that tells the LLM to adjust these feature bullets for an advertisement for this soft drink for the Fourth of July holiday\n",
        "\n",
        "Now let's put our AI to work! We have product feature bullets and want to transform them into Fourth of July themed marketing content.\n",
        "\n",
        "**Prompting Best Practices:**\n",
        "1. **Be specific**: Tell the AI exactly what format/style you want\n",
        "2. **Provide context**: Include all relevant information (the product features)\n",
        "3. **Set expectations**: Specify the output format if needed\n",
        "\n",
        "Below, we'll provide the product features and ask the AI to adapt them for the holiday.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Base Prompt---\n",
            "*   **LIBERTY WITHOUT THE GUILT:** Celebrate your independence from sugar! Canada Dry Ginger Ale Zero Sugar lets you enjoy the BBQ and fireworks without the sugary surrender.\n",
            "\n",
            "*   **SPARKLING CELEBRATION IN A SIP:** Uncap pure refreshment! The crisp, clean taste of Canada Dry Zero Sugar is your instant ticket to relaxation amidst the festive fun.\n",
            "\n",
            "*   **FIZZ-TASTIC FIREWORKS FOR YOUR TASTE BUDS:** Every sip is a burst of bubbly flavor! Let the refreshing ginger taste of Canada Dry Zero Sugar light up your palate and keep you cool all day long.\n",
            "\n",
            "*   **ALL-DAY INDEPENDENCE, ALL-NIGHT ENJOYMENT:** From picnics to sparklers, enjoy the crisp, clean taste of Canada Dry Zero Sugar, any time, without the caffeine.\n",
            "\n",
            "*   **STAR-SPANGLED COCKTAILS & MOCKTAILS:** Mix up your patriotic punch! Canada Dry Ginger Ale Zero Sugar is the perfect addition to your festive cocktails or simply enjoy its refreshing taste on its own!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Original product feature bullets for Canada Dry Ginger Ale Zero Sugar\n",
        "feature_bullets = \"\"\"\n",
        "    ZERO SUGAR: The great taste of Canada Dry Ginger Ale Zero Sugar is also caffeine-free so you can enjoy it guilt-free any time of day\n",
        "    RELAXING & REFRESHING: Sip into your comfort zone with Canada Dry Zero Sugar\n",
        "    CARBONATED SODA: Carbonated soda that tickles your senses with bubbly flavor and refreshing ginger taste that satisfies your thirst every time\n",
        "    CAFFEINE FREE: The great taste of Canada Dry Ginger Ale without caffeine so you can enjoy it any time of day\n",
        "    COCKTAIL MIXER: Canada Dry Ginger Ale Zero Sugar is the perfect mixer for delicious, modern cocktails or to enjoy all by itself\n",
        "\"\"\"\n",
        "\n",
        "print(\"---Base Prompt---\")\n",
        "\n",
        "# Craft a clear, specific prompt\n",
        "prompt = f\"\"\"\n",
        "Transform the following product feature bullets into engaging Fourth of July themed \n",
        "marketing content. Make it feel festive, patriotic, and perfect for summer celebrations.\n",
        "\n",
        "Keep the same number of bullet points, but rewrite each one to tie into Independence Day \n",
        "themes like BBQs, fireworks, family gatherings, and summer fun.\n",
        "\n",
        "Original Feature Bullets:\n",
        "{feature_bullets}\n",
        "\n",
        "Rewritten Fourth of July Feature Bullets:\n",
        "\"\"\"\n",
        "\n",
        "# Generate content using the model\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What Just Happened?\n",
        "\n",
        "1. We sent our prompt (with the product features) to the Gemini model\n",
        "2. The model used its training + our system instructions to generate relevant content\n",
        "3. The response came back as plain text\n",
        "\n",
        "Notice how the AI:\n",
        "- Kept the core product benefits\n",
        "- Added Fourth of July themes (patriotism, BBQs, fireworks)\n",
        "- Maintained an engaging, marketing-friendly tone\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Structured Output (JSON)\n",
        "\n",
        "### Convert this response to a structured output where each feature bullet is an item in a list\n",
        "\n",
        "Plain text is great for humans, but what if we need to use this data in an application? That's where **structured output** comes in!\n",
        "\n",
        "**Why use structured output?**\n",
        "- ‚úÖ Easy to parse in code (no regex needed!)\n",
        "- ‚úÖ Consistent format every time\n",
        "- ‚úÖ Can be stored in databases directly\n",
        "- ‚úÖ Works great with APIs and frontend applications\n",
        "\n",
        "**How it works:**\n",
        "We define a **schema** (structure) that tells the AI exactly what format to return.\n",
        "\n",
        "See [Google's documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) for more on structured output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Structured Output---\n",
            "[\n",
            "  {\n",
            "    \"title\": \"ZERO SUGAR\",\n",
            "    \"description\": \"Guilt-free refreshment for your Fourth of July BBQ! Enjoy the classic taste of Canada Dry Ginger Ale Zero Sugar without any sugar, perfect for a day of celebration.\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"RELAXING & REFRESHING\",\n",
            "    \"description\": \"Unwind with the crisp, clean taste of Canada Dry Zero Sugar. The perfect way to cool off and relax during those long, sunny Independence Day celebrations.\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"CARBONATED SODA\",\n",
            "    \"description\": \"Sparkling ginger taste that adds a festive fizz to your Fourth! The bubbly flavor of Canada Dry Zero Sugar is a refreshing treat for firework viewing or backyard fun.\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"CAFFEINE FREE\",\n",
            "    \"description\": \"Enjoy Canada Dry Ginger Ale Zero Sugar all day and night! Caffeine-free so you can sip freely from your first BBQ burger to the last firework sparkle.\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"COCKTAIL MIXER\",\n",
            "    \"description\": \"Mix up the perfect patriotic cocktails! Canada Dry Ginger Ale Zero Sugar is your go-to mixer for festive drinks that will impress at any Independence Day gathering.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(\"---Structured Output---\")\n",
        "\n",
        "# Define the schema for our response\n",
        "# We want a list of feature bullets, each with a title and description\n",
        "response_schema = {\n",
        "    \"type\": \"array\",\n",
        "    \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"title\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Short title for the feature (e.g., 'ZERO SUGAR')\"\n",
        "            },\n",
        "            \"description\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The Fourth of July themed marketing description\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"title\", \"description\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Generate with structured output configuration\n",
        "response = model.generate_content(\n",
        "    prompt, \n",
        "    generation_config=GenerationConfig(\n",
        "        response_mime_type=\"application/json\",  # Tell the model to return JSON\n",
        "        response_schema=response_schema          # Provide the structure to follow\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Understanding the Schema\n",
        "\n",
        "The schema we defined tells the AI:\n",
        "- Return an **array** (list) of items\n",
        "- Each item is an **object** with two properties:\n",
        "  - `title`: A string for the feature name\n",
        "  - `description`: A string for the marketing copy\n",
        "\n",
        "Now you can easily parse this JSON in Python:\n",
        "```python\n",
        "import json\n",
        "features = json.loads(response.text)\n",
        "for feature in features:\n",
        "    print(f\"{feature['title']}: {feature['description']}\")\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Step 8: Few-Shot Prompting\n",
        "\n",
        "### Use another soft drink's description to create an example to improve the response\n",
        "\n",
        "**What is Few-Shot Prompting?**\n",
        "\n",
        "Few-shot prompting is a technique where you provide examples of the desired input-output pairs before asking for a new generation. It's like showing someone \"here's what I want\" before asking them to do it.\n",
        "\n",
        "**Types of prompting:**\n",
        "- **Zero-shot**: No examples, just instructions (what we did before)\n",
        "- **One-shot**: One example provided\n",
        "- **Few-shot**: Multiple examples provided (typically 2-5)\n",
        "\n",
        "**Why does it work?**\n",
        "Examples help the AI understand:\n",
        "- The exact format you want\n",
        "- The tone and style to use\n",
        "- The level of detail expected\n",
        "- How to transform the input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Few Shot Prompting---\n",
            "Here's your Fourth of July themed content for Canada Dry Ginger Ale Zero Sugar:\n",
            "\n",
            "    ZERO SUGAR: Celebrate freedom and flavor with Canada Dry Ginger Ale Zero Sugar! The great taste without the guilt makes it perfect for all-day Independence Day enjoyment.\n",
            "    RELAXING & REFRESHING: Find your cool zone this Fourth of July with the crisp, clean taste of Canada Dry Zero Sugar ‚Äì the perfect refreshing companion for fireworks and festivities.\n",
            "    CARBONATED SODA: Add some sparkle to your celebration! The bubbly flavor and refreshing ginger taste of Canada Dry Zero Sugar will light up your taste buds.\n",
            "    CAFFEINE FREE: Enjoy the party from sunrise to fireworks! Canada Dry Ginger Ale Zero Sugar is caffeine-free, so you can sip freely all day and night.\n",
            "    COCKTAIL MIXER: Be the star bartender of your Fourth of July bash! Canada Dry Ginger Ale Zero Sugar is the ultimate mixer for creating refreshing cocktails that will wow your guests.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example input: Sprite feature bullets (original)\n",
        "soft_drink_2 = \"\"\"\n",
        "    Quench your thirst with refreshing Sprite\\u00a0soda\\u200b\n",
        "    Clear, crisp\\u00a0lemon-lime soda\\u00a0will keep you invigorated and inspired\\u200b\n",
        "    A delicious\\u00a0citrus taste\\u00a0that knows how to keep things cool\\u200b\n",
        "    Caffeine-free, full of 100% natural flavors\n",
        "    12 fl oz can 12 pack to help you cut through the noise\n",
        "\"\"\"\n",
        "\n",
        "# Example output: How we want the Fourth of July version to look\n",
        "fourth_of_july_sd2 = \"\"\"\n",
        "    Refreshing Sprite soda will keep your Independence Day celebrations light and bright.\n",
        "    Its clear, crisp lemon-lime burst adds the perfect sparkle to your backyard BBQ or picnic.\n",
        "    A delicious citrus taste that adds a cool blast - ideal for hot summer days and fiery fireworks.\n",
        "    Caffeine-free and made with 100% natural flavors, the whole family can enjoy it all day long.\n",
        "    Stock up for your festivities with the convenient 12-pack of 12 fl oz cans - plenty of crisp refreshment for every guest!\n",
        "\"\"\"\n",
        "\n",
        "print(\"---Few Shot Prompting---\")\n",
        "\n",
        "# Build a few-shot prompt with an example\n",
        "prompt = f\"\"\"\n",
        "Transform product feature bullets into Fourth of July themed marketing content.\n",
        "\n",
        "Here is an example of how to do this:\n",
        "\n",
        "EXAMPLE INPUT (Original Sprite Features):\n",
        "{soft_drink_2}\n",
        "\n",
        "EXAMPLE OUTPUT (Fourth of July Themed):\n",
        "{fourth_of_july_sd2}\n",
        "\n",
        "Now, apply the same transformation to this product:\n",
        "\n",
        "INPUT (Original Canada Dry Features):\n",
        "{feature_bullets}\n",
        "\n",
        "OUTPUT (Fourth of July Themed):\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparing Results\n",
        "\n",
        "Compare the few-shot result to the zero-shot result from Step 6. You might notice:\n",
        "- More consistent formatting; Note, all the bullet titles now remain the same but the content is still modified based on our theme prompt\n",
        "- Similar tone and style to the example\n",
        "- Better alignment with your expectations\n",
        "\n",
        "**When to use few-shot prompting:**\n",
        "- When you need very specific formatting\n",
        "- When zero-shot results aren't quite right\n",
        "- When you want consistent output across multiple requests\n",
        "- When the task is complex or nuanced\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß™ LAB WORK\n",
        "\n",
        "Now it's your turn! Complete the following exercises to practice what you've learned.\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 1: Create a Marketing Email\n",
        "**Task:** Using Vertex AI, convert the feature bullets for Canada Dry Ginger Ale into a marketing email.\n",
        "\n",
        "**Hints:**\n",
        "- Include a catchy subject line\n",
        "- Add a greeting and sign-off\n",
        "- Make it feel personal and engaging\n",
        "- Include a call-to-action (e.g., \"Shop now!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Lab Solution 1---\n",
            "Okay, here's a marketing email designed to promote Canada Dry Ginger Ale Zero Sugar, tailored for health-conscious consumers:\n",
            "\n",
            "**Subject: Zero Guilt, All the Refreshment: Canada Dry Zero Sugar is Here!**\n",
            "\n",
            "Hi [Name],\n",
            "\n",
            "Looking for a bubbly, refreshing treat without the sugar rush? We get it! That's why we're so excited about Canada Dry Ginger Ale Zero Sugar. You can dive into that classic ginger taste you love, knowing it's completely guilt-free. It's the perfect way to add a little sparkle to your day, any time of day.\n",
            "\n",
            "Imagine kicking back with the soothing fizz of Canada Dry Zero Sugar, knowing you're making a choice that's both delicious and smart. Plus, it's caffeine-free, so you can sip and relax, whether it's afternoon or evening. Feeling a little fancy? Canada Dry Zero Sugar also makes a fantastic mixer for cocktails! The possibilities are endless.\n",
            "\n",
            "Ready to experience guilt-free refreshment? Find Canada Dry Ginger Ale Zero Sugar at your local grocery store today!\n",
            "\n",
            "Cheers to a refreshing day!\n",
            "\n",
            "The Canada Dry Team\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"---Lab Solution 1---\")\n",
        "\n",
        "# Your solution here!\n",
        "# Hint: Create a prompt that asks for an email format\n",
        "\n",
        "email_prompt = f\"\"\"\n",
        "Create a marketing email promoting Canada Dry Ginger Ale Zero Sugar.\n",
        "\n",
        "Use these product features as your source material:\n",
        "{feature_bullets}\n",
        "\n",
        "The email should include:\n",
        "- A catchy subject line\n",
        "- A friendly greeting\n",
        "- 2-3 paragraphs highlighting the key benefits\n",
        "- A clear call-to-action\n",
        "- A professional sign-off\n",
        "\n",
        "Make it feel personal and engaging, targeting health-conscious consumers who love refreshing drinks.\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(email_prompt)\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Exercise 2: Out of Office Message\n",
        "**Task:** Write a one sentence out of office message for Microsoft Teams for the Fourth of July with a polite tone.\n",
        "\n",
        "**Hints:**\n",
        "- Keep it brief (one sentence)\n",
        "- Mention the holiday\n",
        "- Include when you'll be back\n",
        "- Maintain a professional but friendly tone\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Lab Solution 2---\n",
            "Happy Fourth of July! I'm out of the office celebrating and will be back on July 5th.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"---Lab Solution 2---\")\n",
        "\n",
        "# Your solution here!\n",
        "\n",
        "ooo_prompt = \"\"\"\n",
        "Write a one sentence out of office message for Microsoft Teams for the Fourth of July holiday.\n",
        "\n",
        "Requirements:\n",
        "- Exactly one sentence\n",
        "- Polite and professional tone\n",
        "- Mention the holiday\n",
        "- Indicate returning on July 5th\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(ooo_prompt)\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Exercise 3: Structured Output - BBQ Pairings\n",
        "**Task:** Generate a list of common BBQ soft drink and meal combinations, in the format `{drink: \"Coca Cola\", meal: \"Hot Dogs\"}`\n",
        "\n",
        "**Hints:**\n",
        "- Use structured output (JSON)\n",
        "- Define a schema for the drink-meal pairs\n",
        "- Ask for 5-10 combinations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Lab Solution 3---\n",
            "[\n",
            "  {\n",
            "    \"drink\": \"Coca-Cola\",\n",
            "    \"meal\": \"Classic Cheeseburger\"\n",
            "  },\n",
            "  {\n",
            "    \"drink\": \"Iced Tea\",\n",
            "    \"meal\": \"Pulled Pork Sandwich\"\n",
            "  },\n",
            "  {\n",
            "    \"drink\": \"Lemonade\",\n",
            "    \"meal\": \"Grilled Chicken\"\n",
            "  },\n",
            "  {\n",
            "    \"drink\": \"Dr. Pepper\",\n",
            "    \"meal\": \"BBQ Ribs\"\n",
            "  },\n",
            "  {\n",
            "    \"drink\": \"Root Beer\",\n",
            "    \"meal\": \"Hot Dogs\"\n",
            "  },\n",
            "  {\n",
            "    \"drink\": \"Ginger Ale\",\n",
            "    \"meal\": \"Grilled Salmon\"\n",
            "  },\n",
            "  {\n",
            "    \"drink\": \"Orange Soda\",\n",
            "    \"meal\": \"Brisket\"\n",
            "  },\n",
            "  {\n",
            "    \"drink\": \"Grape Soda\",\n",
            "    \"meal\": \"Veggie Skewers\"\n",
            "  }\n",
            "]\n",
            "\n",
            "üìã BBQ Pairings:\n",
            "  1. Coca-Cola + Classic Cheeseburger\n",
            "  2. Iced Tea + Pulled Pork Sandwich\n",
            "  3. Lemonade + Grilled Chicken\n",
            "  4. Dr. Pepper + BBQ Ribs\n",
            "  5. Root Beer + Hot Dogs\n",
            "  6. Ginger Ale + Grilled Salmon\n",
            "  7. Orange Soda + Brisket\n",
            "  8. Grape Soda + Veggie Skewers\n"
          ]
        }
      ],
      "source": [
        "print(\"---Lab Solution 3---\")\n",
        "\n",
        "# Your solution here!\n",
        "\n",
        "bbq_prompt = \"\"\"\n",
        "Generate a list of 8 classic BBQ soft drink and meal pairings that would be popular at \n",
        "an American summer cookout. Include a variety of drinks and meals.\n",
        "\"\"\"\n",
        "\n",
        "# Define the schema for drink-meal pairs\n",
        "bbq_schema = {\n",
        "    \"type\": \"array\",\n",
        "    \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"drink\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Name of the soft drink\"\n",
        "            },\n",
        "            \"meal\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Name of the BBQ food item\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"drink\", \"meal\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = model.generate_content(\n",
        "    bbq_prompt,\n",
        "    generation_config=GenerationConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=bbq_schema\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)\n",
        "\n",
        "# Bonus: Pretty print the results\n",
        "import json\n",
        "pairings = json.loads(response.text)\n",
        "print(\"\\nüìã BBQ Pairings:\")\n",
        "for i, pair in enumerate(pairings, 1):\n",
        "    print(f\"  {i}. {pair['drink']} + {pair['meal']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéâ Congratulations!\n",
        "\n",
        "You've completed Lab 1! Here's what you learned:\n",
        "\n",
        "| Concept | What You Learned |\n",
        "|---------|------------------|\n",
        "| **Vertex AI Setup** | How to initialize and configure the SDK |\n",
        "| **System Instructions** | How to define the AI's role and behavior |\n",
        "| **Basic Prompting** | How to write clear, effective prompts |\n",
        "| **Structured Output** | How to get JSON responses with schemas |\n",
        "| **Few-Shot Prompting** | How to use examples to improve output quality |\n",
        "\n",
        "## What's Next?\n",
        "\n",
        "In the next session, we'll dive into **Retrieval Augmented Generation (RAG)** - a technique that lets you enhance LLM responses with your own data!\n",
        "\n",
        "##  Additional Resources\n",
        "\n",
        "- [Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs)\n",
        "- [Gemini API Reference](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini)\n",
        "- [Prompt Engineering Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)\n",
        "- [Structured Output Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
